{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01749071",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import transformers\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206df0e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/drive/MyDrive/train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc52616",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a042a03",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c12b5c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddefb17a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df['is_recommended'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b8b5d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e6363f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df[['is_recommended', 'sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329efb0d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load and prepare the dataset\n",
    "def load_and_prepare_data(df):\n",
    "    \"\"\"\n",
    "    Prepare dataframe for sentiment analysis\n",
    "    \"\"\"\n",
    "    print(f\"Preparing data...\")\n",
    "\n",
    "    # Check missing values in important columns\n",
    "    print(\"Missing values:\")\n",
    "    print(df[['review_text', 'is_recommended']].isnull().sum())\n",
    "\n",
    "    # Drop rows with missing reviews or target values\n",
    "    df = df.dropna(subset=['review_text', 'is_recommended'])\n",
    "\n",
    "    # Combine review title and text if title exists\n",
    "    if 'review_title' in df.columns:\n",
    "        df['full_review'] = df['review_title'].fillna('') + \" \" + df['review_text']\n",
    "    else:\n",
    "        df['full_review'] = df['review_text']\n",
    "\n",
    "    # Convert target to binary (0 or 1)\n",
    "    df['target'] = df['is_recommended'].astype(int)\n",
    "\n",
    "    # Print basic statistics\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    print(f\"Recommended count: {df['target'].sum()} ({df['target'].mean()*100:.1f}%)\")\n",
    "    print(f\"Not recommended count: {len(df) - df['target'].sum()} ({(1-df['target'].mean())*100:.1f}%)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Create PyTorch dataset\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, targets, tokenizer, max_len=128):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.reviews[idx])\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'target': torch.tensor(target, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Training function with progress bar\n",
    "def train_epoch(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        targets = batch['target'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=targets\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        total_predictions += len(targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Update progress bar with current loss and accuracy\n",
    "        current_acc = torch.sum(preds == targets).double() / len(targets)\n",
    "        progress_bar.set_postfix({'loss': f\"{loss.item():.4f}\", 'acc': f\"{current_acc:.4f}\"})\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    return np.mean(losses), correct_predictions.double() / total_predictions\n",
    "\n",
    "# Evaluation function\n",
    "def eval_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            targets = batch['target'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=targets\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            total_predictions += len(targets)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            actual_labels.extend(targets.cpu().tolist())\n",
    "\n",
    "    accuracy = correct_predictions.double() / total_predictions\n",
    "    return np.mean(losses), accuracy, predictions, actual_labels\n",
    "\n",
    "# Model training function\n",
    "def train_sentiment_model(train_file, val_file, test_file, model_save_path='best_model.bin'):\n",
    "    # Model parameters\n",
    "    RANDOM_SEED = 42\n",
    "    MAX_LEN = 128\n",
    "    BATCH_SIZE = 16  # Adjust based on your GPU memory\n",
    "    EPOCHS = 3\n",
    "    LEARNING_RATE = 3e-5\n",
    "    PATIENCE = 2  # Early stopping patience\n",
    "\n",
    "    # Set random seeds\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "    # Load data files\n",
    "    try:\n",
    "        print(f\"Loading training data from {train_file}...\")\n",
    "        train_df_raw = pd.read_csv(train_file)\n",
    "\n",
    "        print(f\"Loading validation data from {val_file}...\")\n",
    "        val_df_raw = pd.read_csv(val_file)\n",
    "\n",
    "        print(f\"Loading test data from {test_file}...\")\n",
    "        test_df_raw = pd.read_csv(test_file)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "    # Apply preprocessing to each dataset\n",
    "    train_df = load_and_prepare_data(train_df_raw)\n",
    "    val_df = load_and_prepare_data(val_df_raw)\n",
    "    test_df = load_and_prepare_data(test_df_raw)\n",
    "\n",
    "    print(f\"Training set: {len(train_df)} samples\")\n",
    "    print(f\"Validation set: {len(val_df)} samples\")\n",
    "    print(f\"Test set: {len(test_df)} samples\")\n",
    "\n",
    "    # Load tokenizer and model\n",
    "    print(\"Loading DistilBERT model and tokenizer...\")\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        'distilbert-base-uncased',\n",
    "        num_labels=2\n",
    "    )\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = ReviewDataset(\n",
    "        reviews=train_df['full_review'].to_list(),\n",
    "        targets=train_df['target'].to_list(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=MAX_LEN\n",
    "    )\n",
    "\n",
    "    val_dataset = ReviewDataset(\n",
    "        reviews=val_df['full_review'].to_list(),\n",
    "        targets=val_df['target'].to_list(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=MAX_LEN\n",
    "    )\n",
    "\n",
    "    test_dataset = ReviewDataset(\n",
    "        reviews=test_df['full_review'].to_list(),\n",
    "        targets=test_df['target'].to_list(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=MAX_LEN\n",
    "    )\n",
    "\n",
    "    # Create data loaders with optimized settings for Colab\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=2\n",
    "    )\n",
    "\n",
    "    # Optimization settings\n",
    "    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "    total_steps = len(train_loader) * EPOCHS\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "      optimizer,\n",
    "      num_warmup_steps=0,\n",
    "      num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    best_accuracy = 0\n",
    "    training_stats = []\n",
    "    no_improvement_count = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f'\\nEpoch {epoch + 1}/{EPOCHS}')\n",
    "        print('-' * 30)\n",
    "\n",
    "        # Training phase\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, optimizer, scheduler, device\n",
    "        )\n",
    "\n",
    "        print(f'Train loss: {train_loss:.4f}, accuracy: {train_acc:.4f}')\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, val_acc, _, _ = eval_model(\n",
    "            model, val_loader, device\n",
    "        )\n",
    "\n",
    "        print(f'Val loss: {val_loss:.4f}, accuracy: {val_acc:.4f}')\n",
    "\n",
    "        # Save training statistics\n",
    "        training_stats.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc.item(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc.item()\n",
    "        })\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_accuracy:\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            best_accuracy = val_acc\n",
    "            no_improvement_count = 0\n",
    "            print(f\"New best model saved to {model_save_path}!\")\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            print(f\"No improvement for {no_improvement_count} epochs\")\n",
    "\n",
    "        # Early stopping\n",
    "        if no_improvement_count >= PATIENCE:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "    # Load best model for final evaluation\n",
    "    print(\"\\nLoading best model for evaluation...\")\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    test_loss, test_acc, predictions, actual_labels = eval_model(\n",
    "        model, test_loader, device\n",
    "    )\n",
    "\n",
    "    print(f'\\nTest accuracy: {test_acc:.4f}')\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(actual_labels, predictions))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(actual_labels, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "\n",
    "    # Plot training and validation metrics\n",
    "    stats_df = pd.DataFrame(training_stats)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(stats_df['epoch'], stats_df['train_loss'], label='Train')\n",
    "    plt.plot(stats_df['epoch'], stats_df['val_loss'], label='Validation')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(stats_df['epoch'], stats_df['train_acc'], label='Train')\n",
    "    plt.plot(stats_df['epoch'], stats_df['val_acc'], label='Validation')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_metrics.png')\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "# Create a prediction function\n",
    "def create_prediction_function(model, tokenizer, max_len=128):\n",
    "    def predict_recommendation(review_text):\n",
    "        model.eval()\n",
    "        encoded_review = tokenizer.encode_plus(\n",
    "            review_text,\n",
    "            max_length=max_len,\n",
    "            add_special_tokens=True,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = encoded_review['input_ids'].to(device)\n",
    "        attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs.logits, dim=1)\n",
    "\n",
    "        return 'Recommended' if preds.item() == 1 else 'Not Recommended'\n",
    "\n",
    "    return predict_recommendation\n",
    "\n",
    "# Run the full pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuration - update with your file paths\n",
    "    train_file = '/content/drive/MyDrive/train_data.csv'\n",
    "    val_file = '/content/drive/MyDrive/val_data.csv'\n",
    "    test_file = '/content/drive/MyDrive/test_data.csv'\n",
    "    model_save_path = '/content/drive/MyDrive/best_sentiment_model.bin'\n",
    "\n",
    "    # Train model with all data files\n",
    "    model, tokenizer = train_sentiment_model(train_file, val_file, test_file, model_save_path)\n",
    "\n",
    "    if model and tokenizer:\n",
    "        # Create prediction function\n",
    "        predict = create_prediction_function(model, tokenizer)\n",
    "\n",
    "        # Test with some examples\n",
    "        examples = [\n",
    "            \"This product is amazing! I love it so much. It works perfectly.\",\n",
    "            \"Waste of money. Broke after a week and customer service was terrible.\",\n",
    "            \"It's okay, not the best but not the worst either.\"\n",
    "        ]\n",
    "\n",
    "        print(\"\\nPrediction Examples:\")\n",
    "        for example in examples:\n",
    "            prediction = predict(example)\n",
    "            print(f\"Review: {example}\")\n",
    "            print(f\"Prediction: {prediction}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
